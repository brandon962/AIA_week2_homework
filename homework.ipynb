{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCHU 4105056004 資工二 許哲維"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手寫數字辨識 & CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.1 匯入 Keras 和模組"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先進行匯入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17824797964294172318\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10968950375\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 5250444501775371106\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) # 查看硬體資源\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "忽略掉不必要的warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.2 下載 mnist 資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下載 Mnist 資料 \n",
    "我們將建立以下 Keras 程式, 下載並讀取 mnist 資料."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.3 讀取和查看mnis資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] train data= 60,000\n",
      "\t[Info] test  data= 10,000\n"
     ]
    }
   ],
   "source": [
    "(X_train_image, y_train_label), (X_test_image, y_test_label) = mnist.load_data()\n",
    "\n",
    "print(\"\\t[Info] train data={:7,}\".format(len(X_train_image)))  \n",
    "print(\"\\t[Info] test  data={:7,}\".format(len(X_test_image))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上可以知道 training data 共有 60,000 筆; testing data 共有 10,000 筆。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看訓練資料\n",
    "接著我們來看載入資料的長相與格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.1 訓練資料是由 images 與 labels 所組成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Shape of train data=(60000, 28, 28)\n",
      "\t[Info] Shape of train label=(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t[Info] Shape of train data=%s\" % (str(X_train_image.shape)))\n",
    "print(\"\\t[Info] Shape of train label=%s\" % (str(y_train_label.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練資料是由 images 與 labels 所組成共有 60,000 筆, 每一筆代表某個數字的影像為 28x28 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.2 定應 plot_image 函數顯示數字影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_image(image):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(2, 2)\n",
    "    plt.imshow(image, cmap='binary') # cmap='binary' 參數設定以黑白灰階顯示\n",
    "    plt.show()\n",
    "def plot_image_color(image):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(2, 2)\n",
    "    plt.imshow(image) # cmap='binary' 參數設定以黑白灰階顯示\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.3 執行 plot_image 函數查看第 0 筆數字影像與 label 資料 \n",
    "\n",
    "以下程式呼叫 plot_image 函數, 傳入 X_train_image[0], 也就是順練資料集的第 0 筆資料, 顯示結果可以看到這是一個數字 5 的圖形: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4404627550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(X_train_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43a01090b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image_color(X_train_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我很好奇他原本的顏色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看多筆訓練資料 images 與 labels\n",
    "\n",
    "接下來我們將建立 plot_images_labels_predict 函數, 可以顯示多筆資料的影像與 label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.1 建立 plot_images_labels_predict() 函數\n",
    "\n",
    "因為後續我們希望能很方便查看數字圖形, 真實的數字與預測結果, 所以我們建立了以下函數:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#預設一次顯示10張\n",
    "def plot_images_labels_predict(images, labels, prediction, idx, num=10):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(12, 14)  \n",
    "    #最多一次顯示25張\n",
    "    if num > 25: num = 25  \n",
    "    for i in range(0, num):  \n",
    "        ax=plt.subplot(5,5, 1+i)  \n",
    "        ax.imshow(images[idx], cmap='binary')  \n",
    "        #如果有輸入prediction的話 len()就會大於0=>顯示L和P\n",
    "        if len(prediction) > 0:  \n",
    "            title = \"label={},predict={}\".format(str(labels[idx]), str(prediction[idx]))  \n",
    "        #如果沒有輸入prediction的話=>只需顯示L\n",
    "        else:  \n",
    "            title = \"label={}\".format(str(labels[idx]))  \n",
    "        ax.set_title(title, fontsize=10)  \n",
    "        ax.set_xticks([]); ax.set_yticks([])  \n",
    "        idx+=1  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.2 查看訓練資料的前 10 筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43a0043a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images_labels_predict(X_train_image, y_train_label, [], 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多層感知器模型資料前處理\n",
    "\n",
    "接下來我們建立 多層感知器模型 (MLP), 我們必須先將 images 與 labels 的內容進行前處理, 才能餵進去 Keras 預期的資料結構。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.1 features (數字影像的特徵值) 資料前處理\n",
    "\n",
    "首先將 image 以 reshape 轉換為二維 ndarray \n",
    "因正常照片為 RGB 三維度，而這邊只有灰階\n",
    "而 Conv2D data 需要多一個維度，在此增加\n",
    "並進行 normalization (Feature scaling): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] xTrain: (60000, 28, 28, 1)\n",
      "\t[Info] xTest: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_Train = X_train_image.reshape(60000, 28, 28).astype('float32')\n",
    "x_Test = X_test_image.reshape(10000, 28, 28).astype('float32')\n",
    "\n",
    "x_Train = x_Train[:,:,:,np.newaxis] #為了能fit進Conv2d需要多加一個維度\n",
    "x_Test = x_Test[:,:,:,np.newaxis]\n",
    "\n",
    "print(\"\\t[Info] xTrain: %s\" % (str(x_Train.shape)))\n",
    "print(\"\\t[Info] xTest: %s\" % (str(x_Test.shape)))\n",
    "  \n",
    "# Normalization\n",
    "x_Train_norm = x_Train/255\n",
    "x_Test_norm = x_Test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO.2 labels (影像數字真實的值) 資料前處理\n",
    "\n",
    "label 標籤欄位原本是 0-9 數字, 而為了配合 Keras 的資料格式, 我們必須進行 One-hot-encoding 將之轉換為 10 個 0 或 1 的組合, 例如數字 7 經過 One-hot encoding 轉換後是 0000001000, 正好對應到輸出層的 10 個神經元. 下面簡單測試過程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_TrainOneHot = np_utils.to_categorical(y_train_label) # 將 training 的 label 進行 one-hot encoding\n",
    "y_TestOneHot = np_utils.to_categorical(y_test_label) # 將測試的 labels 進行 one-hot encoding\n",
    "\n",
    "print(y_train_label[0]) # 檢視 training labels 第一個 label 的值\n",
    "print(y_TrainOneHot[0]) # 檢視第一個 label 在 one-hot encoding 後的結果, 會在第六個位置上為 1, 其他位置上為 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "首先我們使用了兩層 Convolution 卷積層並以 Relu 為 activation function\n",
    "以及各對應的 Pooling.\n",
    "再來接上多層感知器 Multilayer Perceptron 模型.\n",
    "輸出層共有 10 個神經元，以 sonftmax 為 activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D => 捲積層:\n",
    "用來把圖片的特徵給抓出來，每張圖片會經過多次不同的捲積圖片，產生出新的圖片，讓機器更好學習它的特徵\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*CO0yrGvAE7jw6JfGqCMRPg.png)\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*AJeWQ88UnmfkJ4_sFOT-YA.png)\n",
    "\n",
    "MaxPooling2D =>池化層:\n",
    "把圖片縮小，在特定大小內選出最大值，將這些最大值組成新的圖片\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*-Yo6iC0S3QLWqgAPnV9knQ.png)\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*CGwpxQT5kJho3CbDZy2Qkw.png)\n",
    "\n",
    "Flatten => 全連接層:\n",
    "圖片都是二為矩陣(這裡採用灰階所以第三為只有1，當二維)，將二為轉為一為矩陣\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*nzZGTF1yypBAQVRVFgvXAA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在層跟層之間通常會Drop掉一定比例的神經元來避免Overfit的狀況，要Drop掉多少比例沒有一個特定的值，通常是25%~50%之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,608,714\n",
      "Trainable params: 1,608,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "  \n",
    "model = Sequential()  # Build Linear Model \n",
    "\n",
    "\n",
    "#Conv layer 1 output shape (64, 28, 28)\n",
    "model.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),  # feature detector 的大小 5x5\n",
    "    padding='same',      # Padding method\n",
    "    input_shape=(28,28,1),\n",
    "    activation='relu'\n",
    "))\n",
    "\n",
    "# MaxPooling layer1 size (2,2)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# Drop 掉一些神經元 避免 overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#全連接層\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(units=128, kernel_initializer='normal', activation='relu')) # Add Input/hidden layer\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax')) # Add Hidden/output layer  \n",
    "print(\"\\t[Info] Model summary:\")  \n",
    "model.summary()  \n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在訓練模型之前, 我們必須先使用 compile 方法, 對訓練模型進行設定, 代碼如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參數說明如下:\n",
    "* **loss** : 設定 loss function, 在深度學習通常使用 cross_entropy (Cross entropy) 交叉摘順練效果較好.\n",
    "* **optimizer** : 設定訓練時的優化方法, 在深度學習使用 adam 可以讓訓練更快收斂, 並提高準確率.\n",
    "* **metrics** : 設定評估模型的方式是 accuracy (準確率)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 0.3512 - acc: 0.8950 - val_loss: 0.0977 - val_acc: 0.9717\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.1020 - acc: 0.9698 - val_loss: 0.0614 - val_acc: 0.9827\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.0706 - acc: 0.9786 - val_loss: 0.0518 - val_acc: 0.9843\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.0550 - acc: 0.9831 - val_loss: 0.0442 - val_acc: 0.9865\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.0462 - acc: 0.9856 - val_loss: 0.0431 - val_acc: 0.9883\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.0391 - acc: 0.9873 - val_loss: 0.0416 - val_acc: 0.9881\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.0338 - acc: 0.9890 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.0292 - acc: 0.9909 - val_loss: 0.0375 - val_acc: 0.9888\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0367 - val_acc: 0.9896\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.0217 - acc: 0.9928 - val_loss: 0.0387 - val_acc: 0.9890\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.0202 - acc: 0.9933 - val_loss: 0.0377 - val_acc: 0.9896\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.0192 - acc: 0.9931 - val_loss: 0.0426 - val_acc: 0.9888\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0353 - val_acc: 0.9900\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "Epoch 15/20\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x=x_Train_norm, \n",
    "                          y=y_TrainOneHot, \n",
    "                          validation_split=0.2, \n",
    "                          epochs=20, \n",
    "                          batch_size=200, \n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面訓練過程會儲存於 train_history 變數中, 參數說明如下: \n",
    "\n",
    "* **x = x_Train_norm** : features 數字的影像特徵值 (60,000 x 784 的陣列)\n",
    "* **y = y_Train_OneHot** : label 數字的 One-hot encoding 陣列 (60,000 x 10 的陣列)\n",
    "* **validation_split = 0.2** : 設定訓練資料與 cross validation 的資料比率. 也就是說會有 0.8 * 60,000 = 48,000 作為訓練資料; 0.2 * 60,000 = 12,000 作為驗證資料.\n",
    "* **epochs** = 10 : 執行 10 次的訓練週期.\n",
    "* **batch_size = 200** : 每一批次的訓練筆數為 200\n",
    "* **verbose = 2** : 顯示訓練過程. 共執行 10 次 epoch (訓練週期), 每批 200 筆, 也就是每次會有 240 round (48,000 / 200 = 240). 每一次的 epoch 會計算 accuracy 並記錄在 train_history 中."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立 show_train_history 顯示訓練過程\n",
    "\n",
    "之前訓練步驟會將每一個訓練週期的 accuracy 與 loss 記錄在 train_history 變數. 我們可以使用下面程式碼讀取 train_history 以圖表顯示訓練過程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "def show_train_history(train_history, train, validation):  \n",
    "    plt.plot(train_history.history[train])  \n",
    "    plt.plot(train_history.history[validation])  \n",
    "    plt.title('Train History')  \n",
    "    plt.ylabel(train)  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['train', 'validation'], loc='upper left')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(train_history, 'acc', 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(train_history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "總共執行 20 個 Epoch 訓練週期, 可以發現:    \n",
    "* 不論訓練與驗證, 誤差越來越低.\n",
    "* 在 Epoch 訓練後期, \"loss 訓練的誤差\" 比 \"val_loss 驗證的誤差\" 小."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_Test_norm, y_TestOneHot)  \n",
    "print()  \n",
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "進行預測\n",
    "前面我們建立模型並於訓練後達成可以接受的 97% 準確率, 接著我們將使用此模型進行預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t[Info] Making prediction to x_Test_norm\")  \n",
    "prediction = model.predict_classes(x_Test_norm)  # Making prediction and save result to prediction  \n",
    "print()  \n",
    "print(\"\\t[Info] Show 10 prediction result (From 240):\")  \n",
    "print(\"%s\\n\" % (prediction[240:250]))  \n",
    "  \n",
    "plot_images_labels_predict(X_test_image, y_test_label, prediction, idx=240)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
